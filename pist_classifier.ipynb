{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8ca0b3bae02029d7",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-10T22:12:26.934400Z",
     "start_time": "2025-09-10T22:12:26.931387Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "matplotlib.use(\"TkAgg\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "HOME_DIRECTORY = os.path.expanduser(\"~\")\n",
    "PISTACHIO_FILE_PATH = os.path.join(HOME_DIRECTORY, \"Documents/\"\n",
    "                                            \"ML@Purdue/\"\n",
    "                                            \"Pistachio Classifier/\"\n",
    "                                            \"Pistachio_Image_Dataset/\"\n",
    "                                            \"Pistachio_Image_Dataset\")\n",
    "BATCH_SIZE = 9\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this cell, we are importing os (for directory functionality), tensorflow for the CNN, and matplotlib. matplotlib.use(\"TkAgg\") was used because the default backend of matplotlib doesn't full support RGB rendering. After the imports, the file path to the data files was created using the os library and batch/epoch sizes of 9 and 10 were chosen arbitrarily."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c42bb0341d97a8f5"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "def load_images():\n",
    "    all_data = tf.keras.utils.image_dataset_from_directory(PISTACHIO_FILE_PATH,\n",
    "                                                           labels='inferred',\n",
    "                                                           label_mode=\"int\",\n",
    "                                                           shuffle=True,\n",
    "                                                           batch_size=BATCH_SIZE)\n",
    "    return all_data\n",
    "\n",
    "\n",
    "def split_data(dataset):\n",
    "    data_size = tf.data.Dataset.cardinality(dataset).numpy()\n",
    "    train_size = int(0.7 * data_size)\n",
    "    val_size = int(0.15 * data_size)\n",
    "\n",
    "    training_set = dataset.take(train_size)\n",
    "    validation_set = dataset.skip(train_size).take(val_size)\n",
    "    test_set = dataset.skip(train_size + val_size)\n",
    "\n",
    "    return training_set, validation_set, test_set\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-10T22:12:29.125289Z",
     "start_time": "2025-09-10T22:12:29.120420Z"
    }
   },
   "id": "b25caba138b20128"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The load_images() function serves to use tensorflow.keras' built in import function to take the image data and convert it directly into a tf.data.Dataset object, the data type that the CNN will take. It is important to note the arguments; label=\"inferred\" allows for automatic labeling of data, label_mode=\"int\" insures numerical labels, shuffle=True shuffles the dataset to ensure randomness, and batch size sets the batch size for the CNN. Then, split_data() takes the dataset and splits it into a training set, validation set, and test set, with each having 70%, 15% and 15% of the dataset respectively."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8b4c2ac4e3f6da6"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "\u001B[1mModel: \"sequential_5\"\u001B[0m\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_5\"</span>\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃\u001B[1m \u001B[0m\u001B[1mLayer (type)                   \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1mOutput Shape          \u001B[0m\u001B[1m \u001B[0m┃\u001B[1m \u001B[0m\u001B[1m      Param #\u001B[0m\u001B[1m \u001B[0m┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ conv2d_16 (\u001B[38;5;33mConv2D\u001B[0m)              │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m255\u001B[0m, \u001B[38;5;34m255\u001B[0m, \u001B[38;5;34m32\u001B[0m)   │           \u001B[38;5;34m416\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_11 (\u001B[38;5;33mMaxPooling2D\u001B[0m) │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m127\u001B[0m, \u001B[38;5;34m127\u001B[0m, \u001B[38;5;34m32\u001B[0m)   │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_17 (\u001B[38;5;33mConv2D\u001B[0m)              │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m126\u001B[0m, \u001B[38;5;34m126\u001B[0m, \u001B[38;5;34m64\u001B[0m)   │         \u001B[38;5;34m8,256\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_12 (\u001B[38;5;33mMaxPooling2D\u001B[0m) │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m63\u001B[0m, \u001B[38;5;34m63\u001B[0m, \u001B[38;5;34m64\u001B[0m)     │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_18 (\u001B[38;5;33mConv2D\u001B[0m)              │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m62\u001B[0m, \u001B[38;5;34m62\u001B[0m, \u001B[38;5;34m128\u001B[0m)    │        \u001B[38;5;34m32,896\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_13 (\u001B[38;5;33mMaxPooling2D\u001B[0m) │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m31\u001B[0m, \u001B[38;5;34m31\u001B[0m, \u001B[38;5;34m128\u001B[0m)    │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_19 (\u001B[38;5;33mConv2D\u001B[0m)              │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m30\u001B[0m, \u001B[38;5;34m30\u001B[0m, \u001B[38;5;34m256\u001B[0m)    │       \u001B[38;5;34m131,328\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_average_pooling2d_5      │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m)            │             \u001B[38;5;34m0\u001B[0m │\n│ (\u001B[38;5;33mGlobalAveragePooling2D\u001B[0m)        │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_5 (\u001B[38;5;33mDropout\u001B[0m)             │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m256\u001B[0m)            │             \u001B[38;5;34m0\u001B[0m │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_5 (\u001B[38;5;33mDense\u001B[0m)                 │ (\u001B[38;5;45mNone\u001B[0m, \u001B[38;5;34m1\u001B[0m)              │           \u001B[38;5;34m257\u001B[0m │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n│ conv2d_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">255</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">255</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">416</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_17 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">126</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">63</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_18 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">62</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ max_pooling2d_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ conv2d_19 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)              │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">30</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ global_average_pooling2d_5      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)        │                        │               │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n├─────────────────────────────────┼────────────────────────┼───────────────┤\n│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n└─────────────────────────────────┴────────────────────────┴───────────────┘\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Total params: \u001B[0m\u001B[38;5;34m173,153\u001B[0m (676.38 KB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">173,153</span> (676.38 KB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Trainable params: \u001B[0m\u001B[38;5;34m173,153\u001B[0m (676.38 KB)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">173,153</span> (676.38 KB)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "\u001B[1m Non-trainable params: \u001B[0m\u001B[38;5;34m0\u001B[0m (0.00 B)\n",
      "text/html": "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n</pre>\n"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_model():\n",
    "    model = tf.keras.models.Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(filters=32,\n",
    "                                     kernel_size=(2, 2),\n",
    "                                     activation=\"relu\",\n",
    "                                     data_format=\"channels_last\",\n",
    "                                     input_shape=(256, 256, 3)))\n",
    "    model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=64,\n",
    "                                     kernel_size=(2, 2),\n",
    "                                     activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=128,\n",
    "                                     kernel_size=(2, 2),\n",
    "                                     activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "    model.add(tf.keras.layers.Conv2D(filters=256,\n",
    "                                     kernel_size=(2, 2),\n",
    "                                     activation=\"relu\"))\n",
    "    model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
    "    model.add(tf.keras.layers.Dropout(0.3))\n",
    "    model.add(tf.keras.layers.Dense(1, activation=\"sigmoid\"))\n",
    "    model.summary()\n",
    "    return model\n",
    "MAIN_MODEL = get_model()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-10T22:12:32.506779Z",
     "start_time": "2025-09-10T22:12:32.461673Z"
    }
   },
   "id": "42c00d955c3cfe81"
  },
  {
   "cell_type": "markdown",
   "source": [
    "This function describes the model architecture. It is a sequential model with alternating Convolutional and Pooling neuron layers with ReLU activation and a final dense neuron with a sigmoid activation. The convolutional layers slide a small 2x2 window over the data (kernel) and identify patterns such as edges or textures (ex. cracks in the pistachios). What is passed to the next layer is a set of feature maps that highlight the specific features the kernel found. The pooling layers downsample (\"pixelate\") the image, condensing the information from the previous layer to make the prediction more resilient to small shifts/distortions in the input. All these parameters are condensed into 256 parameters representing each feature, and this was put into one dense neuron with one output. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b0eb6894d89f21d6"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2148 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "DATASET = load_images()\n",
    "TRAIN_SET, VAL_SET, TEST_SET = split_data(DATASET)\n",
    "PISTA_NAMES = DATASET.class_names"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-10T22:12:37.761759Z",
     "start_time": "2025-09-10T22:12:37.687989Z"
    }
   },
   "id": "8f5e1bb66ce8e4eb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "These serve to initialize the training, validation, and test sets, as well as to retrieve the names of the different classes of pistachio."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cf1ee620bae86ac8"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "MAIN_MODEL.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss=\"binary_crossentropy\",\n",
    "              metrics=[\"accuracy\", tf.keras.metrics.AUC(name=\"auc\")])\n",
    "training_bool = input(\"Do you want to train? Y/N  \")\n",
    "if training_bool == \"Y\":\n",
    "    train = MAIN_MODEL.fit(TRAIN_SET, epochs=EPOCHS,\n",
    "                    validation_data=VAL_SET)\n",
    "    MAIN_MODEL.save(\"pistachio_cnn.keras\")\n",
    "elif training_bool == \"N\":\n",
    "    MAIN_MODEL = tf.keras.models.load_model(\"pistachio_cnn.h5\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-10T22:12:42.430213Z",
     "start_time": "2025-09-10T22:12:39.190663Z"
    }
   },
   "id": "1f850cad36f68c2"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we compile the model, using the Adam optimizer with a learning rate of 0.001. This learning rate is a general standard, as it is usually small enough to not let the minimization function diverge but also big enough that the minimization won't get stuck in a local minima. We use the Adam optimizer because it can carry over \"momentum\" from previous gradients by remembering the updates it made in the past. It also adapts the learning rate depending on the gradient, making sure it doesn't get too large or too small depending on the scenario. We also measure the accuracy of the model using the Area Under the ROC curve, with 0.5 being random classification and 1 being perfect classification. Finally, in order to ensure training doesn't occur every time, I've given the user an option to train or not. If the input is Y, the model will train, save the model and test. If the answer is N, the program simply loads in the most recent training run and tests on that."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "90e7145876e788e2"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m37/37\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m2s\u001B[0m 34ms/step - accuracy: 0.8364 - auc: 0.9063 - loss: 0.4245\n",
      "Test loss: 0.4245\n",
      "Test accuracy: 0.8364\n",
      "Test AUC: 0.9063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-10 18:13:21.093084: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc, test_auc = MAIN_MODEL.evaluate(TEST_SET)\n",
    "print(f\"Test loss: {test_loss:.4f}\")\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")\n",
    "print(f\"Test AUC: {test_auc:.4f}\")\n",
    "\n",
    "for images, labels in TEST_SET.take(1):\n",
    "    probabilities = MAIN_MODEL.predict_on_batch(images)\n",
    "    predictions = (probabilities >= 0.5).astype(int).ravel()\n",
    "\n",
    "    plt.figure(figsize=(10.0, 10.0))\n",
    "    for i in range(len(images)):\n",
    "        new_sub = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(int))\n",
    "        new_sub.axis(\"off\")\n",
    "        true_label = int(labels[i].numpy())\n",
    "        pred_label = int(predictions[i])\n",
    "        title = (f\"Prediction: {PISTA_NAMES[pred_label]} ({probabilities[i][0]:.3f})\\n\"\n",
    "                 f\"Actual: {PISTA_NAMES[true_label]}\")\n",
    "        color = \"green\" if (true_label == pred_label) else \"red\"\n",
    "        plt.title(title, color=color, fontsize=9)\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-09-10T22:13:21.102306Z",
     "start_time": "2025-09-10T22:13:10.210136Z"
    }
   },
   "id": "initial_id"
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this final cell, we evaluate the model using the test set and create a plot that shows the images of one batch of the test set, along with the predicted and actual classifications. If the classification is right, the text is green, and if it is wrong the text is red."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f3d3773b027bbf2f"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a132a3c44a159136"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
